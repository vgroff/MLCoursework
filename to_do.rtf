{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf100
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 What we\'92ve got so far:\
\
\
\
-building a single tree training yes/no on a single variable (out of 6)\
- can print and visualise a tree\
- function in Tree that will divide a given matrix into lists of lists for cross-validation\
- general function for building a confusion matrix from column vectors of real/actual classes.\
\
\
To do:\
\
\
- unify into a single model (probably array of 6 trees) based on different variables\
- come up with a single classifier for the overall model (suggest highest probability for the case of >1 positive, or lowest probability if no positives)\
\
- come up with the testing routine for the k-fold cross validation, building the confusion matrix as we go and then come up with the performance metrics in the document.\
\
- figure out the pruning routine which is automated for MATLAB, not sure how to adapt it to Python yet.}